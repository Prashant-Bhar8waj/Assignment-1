{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "T-21tlRxnfLW"
   },
   "source": [
    "# SNLP Assignment 1\n",
    "\n",
    "Name 1: <br/>\n",
    "Student id 1: <br/>\n",
    "Email 1: <br/>\n",
    "\n",
    "\n",
    "Name 2: <br/>\n",
    "Student id 2: <br/>\n",
    "Email 2: <br/> \n",
    "\n",
    "**Instructions:** Read each question carefully. <br/>\n",
    "Make sure you appropriately comment your code wherever required. Your final submission should contain the completed Notebook and the respective Python files for exercise 2,  and the bonus question (if you attempt it). There is no need to submit the data files. <br/>\n",
    "Upload the zipped folder on CMS. Please follow the naming convention of **Name1_studentID1_Name2_studentID2.zip**. Make sure to click on \"Turn-in\" (or the equivalent on CMS) after your upload your submission, otherwise the assignment will not be considered as submitted. Only one member of the group should make the submisssion.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (3 = 1+2 points)\n",
    "Let's revise probability, here are some notations used in this exercise: \n",
    "- $S$: Sample Space\n",
    "- Uni-gram: One token/letter i.e. $a, b, c$\n",
    "- Bi-gram: Two tokens/letters i.e. $(a,b), (b,c), (c,d)$\n",
    "- $p(x,y)$: Probability of $x$ followed by $y$\n",
    "- $pR(x)$: Probability of $x$ being the right hand bi-gram member i.e. bi-grams like $(z,x), (a,x), (x,x)$\n",
    "- $pL(x)$: Probability of $x$ being the left hand bi-gram member i.e. bi-grams like $(x,y), (x,p), (x,n)$\n",
    "\n",
    "Let $S = { a, b, c }$ and $p$ be the joint distribution on a sequence of two events (i.e. on $S$ x $S$, ordered). If you know that \n",
    "- $p(a,a)$ = 0.25, \n",
    "- $p(c,c)$ = 0.25, \n",
    "- $p(b,a)$ = 0.125, \n",
    "- $p(b,b)$ = 0, \n",
    "- $p(a,c)$ = 0.25, \n",
    "- $pL(a)$ [unigram probability of a as a left-hand bigram member] = .5, \n",
    "- $pR(b)$ [unigram probability of b as the right-hand bigram member] = 0.125\n",
    "\n",
    "is it enough to compute p(b|c) (i.e., the probability of seeing b if we already know that the preceding event generated c)? Justify your answer. (3-5 sentences) Please use $\\LaTeX$ styling for equations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add any necessary import/download statements here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0o_hqMzc7qAH"
   },
   "source": [
    "## Exercise 2 (7 = 4+0.5+1+0.5+1 points)\n",
    "\n",
    "The following cell executes the function `analysis` from the `exercise_2.py` file. You are given a tokenized input (list of words). \n",
    "\n",
    "1. Plot the frequencies against rank for the inputs (different languages) along with an 'ideal' curve according to the Zipf's law. Use the log-log scale. (4 = (1 *4) points)\n",
    "\n",
    "Then, answer the following questions and elaborate:\n",
    "\n",
    "2. Does Zipf's law form an accurate prediction of your data? (0.5 point)\n",
    "3. What are the differences between the languages? What causes them? (1 point)\n",
    "4. In your plot, what causes the vertical gaps (\"steps\") for high-rank words  (rightmost)? (0.5 point)\n",
    "5. Zipf's law \"predicts\" the frequency of the n-th rank word. Compute the mean squared error of these predictions $\\big(\\frac{1}{n} \\sum (\\hat{y} - y)^2\\big)$, and output the value to 10 decimal digits. (1 point)\n",
    "\n",
    "Please extend `exercise_2.py`. Ideally the following cell remains unchanged and outputs your code. If you make changes, please comment on why it was necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 915
    },
    "id": "-QsrwdIsA2gJ",
    "outputId": "f7ffcf9e-d4df-47ea-87b4-c4205a3c6d9d"
   },
   "outputs": [],
   "source": [
    "import tokenize\n",
    "from importlib import reload\n",
    "exercise_2 = reload(exercise_2)\n",
    "\n",
    "# run on English text\n",
    "with open(\"data/macbeth_en.txt\", \"r\") as f:\n",
    "    exercise_2.analysis(\"English\", f.read().lower().split())\n",
    "\n",
    "# run on German text\n",
    "with open(\"data/macbeth_de.txt\", \"r\") as f:\n",
    "    exercise_2.analysis(\"German\", f.read().lower().split())\n",
    "\n",
    "# run on PIRATES OF THE CARRIBEAN: DEAD MAN'S CHEST\n",
    "# TODO: Use NLTK's corpora for loading this text\n",
    "# and call the function as done above\n",
    "\n",
    "# Run on Transformer's trainer module's source code\n",
    "with open(\"data/trainer.py\", \"r\") as f:\n",
    "    tokens = [\n",
    "        x.string\n",
    "        for x in tokenize.generate_tokens(f.readline)\n",
    "        if x.type not in {\n",
    "            tokenize.COMMENT, tokenize.STRING, tokenize.INDENT, tokenize.DEDENT, tokenize.NEWLINE\n",
    "        }\n",
    "    ]\n",
    "    exercise_2.analysis(\"Python\", tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YyWwTwR0-bcq"
   },
   "source": [
    "# Bonus (2 point)\n",
    "\n",
    "Repeat exercise 2 but run these two experiments (independent of each other):\n",
    " - Don't lowercase anything\n",
    " - Use character level tokenization, rather than word level\n",
    "\n",
    "Please write your own loader similar to the one we provided. For this, you may create a file `bonus.py` and import your code from there in a similar fashion to the above questions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
